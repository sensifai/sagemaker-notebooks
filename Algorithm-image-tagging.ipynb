{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Sensifai](https://sensifai.com) Image Tagging\n",
    "Sensifai offers one of the most accurate Deep Learning training platform to train your image recognition system and incorporate it into your application. This product lets you access Sensifai's advanced image recognition algorithm and train it with our own data and validate it with any set you would like. \n",
    "\n",
    "## Step 1: preparing your data\n",
    "Before starting the training job you have to prepare your data and copy the files to S3. Our training algorithm only supports image data formats. you can simply prepare your data by following one of the methods below:\n",
    "\n",
    "- if you have a validation set, copy images of train/validation in separate train/validation folders. also, you need to prepare separate label files in CSV format for your data splits(train.csv, validation.csv) and copy them under their corresponding folders.\n",
    "- if you do not provide a separate validation set, you can simply copy all your images in train folder and provide a labels.csv file. The algorithm will separate your data based on the min_val_samples parameter.\n",
    "\n",
    "Our algorithm only supports image file formats for training, but for inference, you could either choose  image or a video version get the results. it's recommended to use images that satisfy the following  conditions:\n",
    "- the algorithm supports most of the common image formats (jpg, jpeg,...) and we do not set any limitation on the image or video types, however, if the algorithm cannot detect a format, it skips the file.  also if the file is corrupted, the algorithm skips it. at training time, if the number of image files that algorithm skip exceeds 50% of all images in the folder the training procedure exited with the failure code.\n",
    "- we do not have strict conditions on the resolution. However, very low-resolution images (lower than 224 * 224) may have a bad effect on training accuracy. also, very high-resolution images take longer time for transferring and preprocessing. \n",
    "- our multilabel algorithm can cope with unbalanced datasets. but it's recommended to have a minimum of ~100 images for a tag, to reach outstanding results.\n",
    "\n",
    "### Label File format:\n",
    "\n",
    "- you should provide a comma-separated CSV file with two columns: image_name, tags. for Multi-Label training, you need to separate tags with space. an example of a valid CSV file is shown below:\n",
    "\n",
    "| image_name      | tags           |\n",
    "| --------------- | -------------- |\n",
    "| image_0001.jpg  | person         |\n",
    "| image_0002.jpg  | tree sky grass |\n",
    "\n",
    "- Make sure to name the files correctly(you should either have train.csv,validation.csv or labels.csv).\n",
    "- It's important to have a balanced dataset in order to reach outstanding results.\n",
    "\n",
    "## uploading files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data file to s3://sensifai-sagemaker-artifacts/algorithm-validation/Tagging/train/\n",
      "uploaded validation data file to s3://sensifai-sagemaker-artifacts/algorithm-validation/Tagging/validation/\n"
     ]
    }
   ],
   "source": [
    "import sagemaker as sage\n",
    "import boto3\n",
    "import time\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = \"your bucket here\"\n",
    "prefix = \"prefix on s3 that the test files are stored\"\n",
    "sess = sage.Session()\n",
    "s3_train=\"s3://{}/{}/train/\".format(bucket,prefix)\n",
    "s3_validation=\"s3://{}/{}/validation/\".format(bucket,prefix)\n",
    "\n",
    "#we already have transfer the data to s3, if you want to copy the files uncomment below code  \n",
    "#s3_train = sess.upload_data(train_data_dir, bucket, \"{}/train\".format(prefix))\n",
    "#s3_validation = sess.upload_data(validation_data_dir, bucket, \"{}/validation\".format(prefix))\n",
    "\n",
    "print(\"uploaded training data file to {}\".format(s3_train))\n",
    "print(\"uploaded validation data file to {}\".format(s3_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### important notes:\n",
    "- currently, we support just \"FileMode\" for input mode. In order to insure that there is enough space for transferring and preprocessing files, please set *ValumeSizeinGB* parameter of the *ResourceConfig* section to 2*size_of_dateset-inGB*)\n",
    "- Choosing a more powerful system does not always lead to better results. Also, choosing a network with more layers is not always the best option. Select the number of layers and the instance type based on the size of dataset and type of input data.\n",
    "\n",
    "## Step 2: Create a model \n",
    "__Training Parameters__\n",
    "\n",
    "\n",
    "| Name                   | Description                                                                                       | IsRequired | IsTunable | DefaultValue | Range                     | Type        |\n",
    "|------------------------|---------------------------------------------------------------------------------------------------|------------|-----------|--------------|---------------------------|-------------|\n",
    "| min_val_samples        | minimum number of validation samples for each tag (if no val label file exists!)                  | False      | False     | 20           | [1, 1000]                 | Integer     |\n",
    "| learning_rate          | Initial learning rate                                                                             | False      | False     | 0.001        | [0.000001, 0.1]           | Continuous  |\n",
    "| momentum               | Momentum                                                                                          | False      | False     | 0.9          | [0, 0.9]                  | Continuous  |\n",
    "| model_depth            | Number of layers for model                                                                        | False      | False     | 101          | 18, 34, 50, 101, 152, 154 | Categorical |\n",
    "| settings               | select Training Setting                                                                           | True       | False     | Multi-Label  | Multi-Label, Single-Label | Categorical |\n",
    "| batch_size             | batch size(if set to 0, will automatically set batch size considering GPU memories)               | False      | False     | 0            | [0, 500]                  | Integer     |\n",
    "| lr_decay               | Factor by which the learning rate will be reduced. new_lr = lr * factor                           | False      | False     | 0.1          | [0.01, 0.9]               | Continuous  |\n",
    "| lr_patience            | Patience of LR scheduler                                                                          | False      | False     | 5            | [1, 100]                  | Integer     |\n",
    "| max_patience           | Terminate training after validation loss become greater than train loss for this number of epochs | False      | False     | 10           | [1, 500]                  | Integer     |\n",
    "| n_epochs               | Total number of training epochs                                                                   | False      | False     | 30           | [1, 1000]                 | Integer     |\n",
    "| result_second_interval | return results for tags in this second Intervals                                                  | False      | False     | 3            | [1, 10]                   | Integer     |\n",
    "| thresholdValue         | Critical Parameter for Selecting Class Labels                                                     | False      | False     | 0.5          | [0.01, 0.95]              | Continuous  |\n",
    "| num_result_tags        | Number of tags(Top n tags) to show in each timestamp of Inference json file                       | False      | False     | 5            | [1, 10]                   | Integer     |\n",
    "| score_result_threshold | Show results greater than this threshold for each timestamp in Inference json file                | False      | False     | 0.5          | [0.0001, 0.99]            | Continuous  |\n",
    "\n",
    "__Run a SageMaker training job__\n",
    "\n",
    "This code will start a training job, wait for it to be done, and report its status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job current status: InProgress\n",
      "Training job ended with status: Completed\n",
      "CPU times: user 349 ms, sys: 21.2 ms, total: 370 ms\n",
      "Wall time: 46min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alg_arn=\"COPY ALGOTITHM ARN HERE \"\n",
    "job_name_prefix = 'train-sensifai-image-tagging'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp\n",
    "\n",
    "create_training_params = \\\n",
    "{   \"TrainingJobName\": job_name,\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"AlgorithmName\":alg_arn,\n",
    "        \"TrainingInputMode\": \"File\",\n",
    "        \"MetricDefinitions\": []\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"EnableNetworkIsolation\":True,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": 's3://{}/{}/output/{}'.format(bucket,prefix, job_name_prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.p2.8xlarge\",\n",
    "        \"VolumeSizeInGB\": 40\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 14400\n",
    "    },\n",
    "    \"HyperParameters\": {\n",
    "        \"min_val_samples\": \"20\",\n",
    "        \"model_depth\": \"101\",\n",
    "        \"result_second_interval\": \"3\",\n",
    "        \"settings\": \"Multi-Label\", \n",
    "        \"learning_rate\": \"0.01\",\n",
    "        \"momentum\": \"0.5\",\n",
    "        \"lr_decay\": \"0.1\", \n",
    "        \"batch_size\": \"0\",\n",
    "        \"lr_patience\": \"5\", \n",
    "        \"max_patience\": \"10\",\n",
    "        \"n_epochs\": \"10\", \n",
    "        \"thresholdValue\": \"0.5\",\n",
    "        \"num_result_tags\": \"5\",\n",
    "        \"score_result_threshold\": \"0.5\"\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3_train,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "sagemaker = boto3.client(service_name='sagemaker')\n",
    "sagemaker.create_training_job(**create_training_params)\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))\n",
    "\n",
    "try:\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "    job_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = job_info['TrainingJobStatus']\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print('Training failed to start')\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 :Create a SageMaker model \n",
    "This will set up the model created during training within SageMaker to be used later for recognition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelArn': 'arn:aws:sagemaker:us-east-2:320478615219:model/sensifai-tagging-2018-11-14-15-40-19', 'ResponseMetadata': {'RequestId': 'd01eab0b-2360-469c-8985-1f1d320d1aae', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'd01eab0b-2360-469c-8985-1f1d320d1aae', 'content-type': 'application/x-amz-json-1.1', 'content-length': '98', 'date': 'Wed, 14 Nov 2018 15:40:19 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name=\"sensifai-tagging\" + timestamp\n",
    "job_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "model_package_arn =  \"Paste the model ARN\"\n",
    "model_creation = {\n",
    "    \"ModelName\": model_name,\n",
    "    \"PrimaryContainer\": {\n",
    "        \"ModelPackageName\": model_package_arn\n",
    "    },\n",
    "    \"ExecutionRoleArn\":role,\n",
    "    \"EnableNetworkIsolation\": True,\n",
    "}\n",
    "\n",
    "model = sagemaker.create_model(**model_creation)\n",
    "sagemaker.describe_model(ModelName = model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: inference with the trained model  (Batch transform)\n",
    "finally the model is ready to serve and you can feed the videos to the model and save the results in output folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded batch data files to s3://sensifai-sagemaker-artifacts/algorithm-validation/Tagging/test/\n",
      "Created Transform job with name:  sensifai-tagging-bt-2018-11-14-15-40-22\n",
      "Transform job ended with status: Completed\n",
      "CPU times: user 163 ms, sys: 5.52 ms, total: 168 ms\n",
      "Wall time: 6min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "s3_batch_input=\"s3://{}/{}/test/\".format(bucket,prefix)\n",
    "#we already have transfer the data to s3, if you want to copy the files uncomment below code  \n",
    "# s3_bath_input = sess.upload_data(batch_input_dir, bucket, \"{}/test\".format(prefix))\n",
    "print(\"uploaded batch data files to {}\".format(s3_batch_input))\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "batch_job_name = \"sensifai-tagging-bt\" + timestamp\n",
    "batch_output = 's3://{}/{}/output/{}'.format(bucket,prefix, batch_job_name)\n",
    "\n",
    "request = \\\n",
    "{\n",
    "  \"TransformJobName\": batch_job_name,\n",
    "  \"MaxConcurrentTransforms\": 0,\n",
    "  \"MaxPayloadInMB\": 0,\n",
    "  \"ModelName\": model_name,\n",
    "  \"TransformInput\": {\n",
    "    \"DataSource\": {\n",
    "      \"S3DataSource\": {\n",
    "        \"S3DataType\": \"S3Prefix\",\n",
    "        \"S3Uri\": s3_batch_input\n",
    "      }\n",
    "    },\n",
    "    \"ContentType\": \"video/mp4\",\n",
    "    \"CompressionType\": \"None\",\n",
    "    \"SplitType\": \"None\"\n",
    "  },\n",
    "  \"TransformOutput\": {\n",
    "    \"S3OutputPath\": batch_output,\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"AssembleWith\": \"Line\"\n",
    "  },\n",
    "  \"TransformResources\": {\n",
    "    \"InstanceType\": \"ml.p2.xlarge\",\n",
    "    \"InstanceCount\": 1\n",
    "  }\n",
    "}\n",
    "\n",
    "sagemaker.create_transform_job(**request)\n",
    "\n",
    "print(\"Created Transform job with name: \", batch_job_name)\n",
    "\n",
    "while(True):\n",
    "    job_info = sagemaker.describe_transform_job(TransformJobName=batch_job_name)\n",
    "    status = job_info['TransformJobStatus']\n",
    "    if status == 'Completed':\n",
    "        print(\"Transform job ended with status: \" + status)\n",
    "        break\n",
    "    if status == 'Failed':\n",
    "        message = job_info['FailureReason']\n",
    "        print('Transform failed with the following error: {}'.format(message))\n",
    "        raise Exception('Transform job failed') \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### download the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sensifai-sagemaker-artifacts/algorithm-validation/Tagging/output/sensifai-tagging-bt-2018-11-14-15-40-22/basket_shot.mp4.out to output/basket_shot.mp4.out\n",
      "download: s3://sensifai-sagemaker-artifacts/algorithm-validation/Tagging/output/sensifai-tagging-bt-2018-11-14-15-40-22/image_0039.jpg.out to output/image_0039.jpg.out\n",
      "download: s3://sensifai-sagemaker-artifacts/algorithm-validation/Tagging/output/sensifai-tagging-bt-2018-11-14-15-40-22/image_0059.jpg.out to output/image_0059.jpg.out\n",
      "download: s3://sensifai-sagemaker-artifacts/algorithm-validation/Tagging/output/sensifai-tagging-bt-2018-11-14-15-40-22/image_0100.jpg.out to output/image_0100.jpg.out\n",
      "download: s3://sensifai-sagemaker-artifacts/algorithm-validation/Tagging/output/sensifai-tagging-bt-2018-11-14-15-40-22/plant.jpg.out to output/plant.jpg.out\n",
      "download: s3://sensifai-sagemaker-artifacts/algorithm-validation/Tagging/output/sensifai-tagging-bt-2018-11-14-15-40-22/image_0079.jpg.out to output/image_0079.jpg.out\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "output_path=\"./output\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "!aws s3 cp $batch_output $output_path --recursive\n",
    "\n",
    "#do anything with json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 5 : cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally uncomment and run the code to clean everything up\n",
    "#sagemaker.delete_model(ModelName= model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
