{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Sensifai](https://sensifai.com) Audio Event Classification\n",
    "Sensifai offers one of the most accurate Deep Learning training platform to train your audio event data and incorporate it into your application. This product lets you access Sensifai's advanced audio event classification algorithm, train it with our own data and validate it with any dataset you would like. Our Multi-Label/Single-Label tagging system let you find general tags in any audio file.\n",
    "\n",
    "## Step 1: Preparing your data\n",
    "Before starting the training job you have to prepare your data and copy the files to S3. generally, you should have 2 separate folders for training and validation files, and also 2 CSV  files named train_samples.csv\n",
    "validation_samples.csv respectively.\n",
    "\n",
    "- All of the audio data should be in the same format, for example, wav or mp3.\n",
    "- the algorithm supports 2 audio formats: Wav and mp3, if the algorithm cannot detect the audio format, skips the file.  also if the file is corrupted, the algorithm skips it. if the number of files that algorithm skip exceeds 50% of all files in the folder, the training procedure exits with the failure code.\n",
    "\n",
    "- the standard audio duration is 10 seconds, it means for audio length less than 10, we will repeat last frames to reach  10 seconds, and for audios longer than 10 seconds, just first 10 seconds will be kept. audio with length less than 5 will be omitted. the prediction is calculated over 1 seconds frame and will be averaged over 10 seconds.\n",
    "- the input CSV contains rows of data, each row contains audio file name without the extension of the file, and it's related tags.  for example, if one of the sample audio files is \"dogbark.wav\"  we have to use \"dogbark\"   instead of the original file name. The second field is a list of class names with double quotes and braces.  for example: \"[Croak, Frog]\" Croak is first class name and Frog is the second one. if the goal is a single-label classification,   you don't need double quotes. An example of some  rows is:\n",
    "\n",
    "570RD5v5HyE,\"[Croak,Frog]\" \n",
    "\n",
    "69C9cBKgsBI,[Lawn mower]\n",
    "\n",
    "bRuJev7JLxA,[Chainsaw]\n",
    "\n",
    "cYqfSDt2B_A,[Frog]\n",
    "\n",
    "- the second field should be exactly the same as example(contains comma between class names and include braces). if you have more than one classes  you should use double quotes\n",
    "\n",
    "\n",
    "\n",
    "## uploading files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data file to s3://sensifai-sagemaker-artifacts/algorithm-validation/audio-event-recognition/train/\n",
      "uploaded validation data file to s3://sensifai-sagemaker-artifacts/algorithm-validation/audio-event-recognition/validation/\n"
     ]
    }
   ],
   "source": [
    "import sagemaker as sage\n",
    "import boto3\n",
    "import time\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = \"your bucket here\"\n",
    "prefix = \"prefix on s3 that the test files are stored\"\n",
    "sess = sage.Session()\n",
    "s3_train=\"s3://{}/{}/train/\".format(bucket,prefix)\n",
    "s3_validation=\"s3://{}/{}/validation/\".format(bucket,prefix)\n",
    "\n",
    "#we already have transfer the data to s3, if you want to copy the files uncomment below code  \n",
    "#s3_train = sess.upload_data(train_data_dir, bucket, \"{}/train\".format(prefix))\n",
    "#s3_validation = sess.upload_data(validation_data_dir, bucket, \"{}/validation\".format(prefix))\n",
    "\n",
    "print(\"uploaded training data file to {}\".format(s3_train))\n",
    "print(\"uploaded validation data file to {}\".format(s3_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### important notes:\n",
    "- currently, we support just \"FileMode\" for input mode. In order to insure that there is enough space for transferring and preprocessing files, please set *ValumeSizeinGB* parameter of the *ResourceConfig* section to 2*size_of_dateset-inGB*)\n",
    "## Step 2: Create a model \n",
    "__Training Parameters__\n",
    "\n",
    "\n",
    "| Name                              |Description                                                                                       | Type       | IsTunable | IsRequired | DefaultValue | Range         |\n",
    "|-----------------------|---------------------------------------------------------------------------------------------------|------------|-----------|------------|--------------|---------------|\n",
    "| data_type             | 0 is mp3 , 1 is wave and default is 1                                                             | Integer    | false     | false      | 1            | [0,1]         |\n",
    "| num_gpus              | data percentage for validation                                                                    | Integer    | false     | false      | 2            | [1,8]         |\n",
    "| num_classes           | Total number of classes                                                                           | Integer    | false     | true       | 3            | [2,527]       |\n",
    "| initial_learning_rate | Initial learning rate                                                                             | Continuous | false     | false      | 0.0001       | [0.00001,0.1] |\n",
    "| multilabel_flag       | 1 is multilabel, 0 is single label                                                                | Integer    | false     | false      | 1            | [0,1]         |\n",
    "| lr_patience           | Patience of LR scheduler                                                                          | Integer    | false     | false      | 5            | [1,100]       |\n",
    "| max_patience          | Terminate training after validation loss become greater than train loss for this number of epochs | Integer    | false     | false      | 10           | [1,100]       |\n",
    "| num_epochs            | Total number of training epochs                                                                   | Integer    | false     | false      | 10           | [1,100]       |\n",
    "| weigghted_loss_flag   | 1 imeans weigghted_loss, 0 is not weighted                                                        | Integer    | false     | false      | 1            | [0,1]         |\n",
    "\n",
    "__Run a SageMaker training job__\n",
    "\n",
    "This code will start a training job, wait for it to be done, and report its status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job current status: InProgress\n",
      "Training failed to start\n",
      "Training failed with the following error: AlgorithmError: Exit Code: 255\n",
      "CPU times: user 121 ms, sys: 17.4 ms, total: 138 ms\n",
      "Wall time: 8min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "alg_arn=\"Paste the algorithm ARN\"\n",
    "job_name_prefix = 'train-sensifai-audio-tagging'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp\n",
    "\n",
    "create_training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": alg_arn,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"EnableNetworkIsolation\":True,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": 's3://{}/{}/output/{}'.format(bucket,prefix, job_name_prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.p2.8xlarge\",\n",
    "        \"VolumeSizeInGB\": 20\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 14400\n",
    "    },\n",
    "    \"HyperParameters\": {\n",
    "\n",
    "    \"data_type\": \"1\", \n",
    "    \"multilabel_flag\": \"1\", \n",
    "    \"max_patience\": \"10\", \n",
    "    \"weigghted_loss_flag\": \"1\", \n",
    "    \"batch_size\": \"360\", \n",
    "    \"initial_learning_rate\": \"0.0001\", \n",
    "    \"num_epochs\": \"5\", \n",
    "    \"num_classes\": \"4\"\n",
    "},\n",
    "    \n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3_train,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3_validation,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "sagemaker = boto3.client(service_name='sagemaker')\n",
    "sagemaker.create_training_job(**create_training_params)\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))\n",
    "\n",
    "try:\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "    job_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = job_info['TrainingJobStatus']\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print('Training failed to start')\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 :Create a SageMaker model \n",
    "This will set up the model created during training within SageMaker to be used later for recognition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelArn': 'arn:aws:sagemaker:us-east-2:320478615219:model/sensifai-audio-tagging-2019-02-24-22-00-42', 'ResponseMetadata': {'RequestId': '56855123-f452-4939-857b-4341c484e12d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '56855123-f452-4939-857b-4341c484e12d', 'content-type': 'application/x-amz-json-1.1', 'content-length': '104', 'date': 'Sun, 24 Feb 2019 22:00:42 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name=\"sensifai-audio-tagging\" + timestamp\n",
    "job_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "model_package_arn =  \"Paste the model ARN\"\n",
    "model_creation = {\n",
    "    \"ModelName\": model_name,\n",
    "    \"PrimaryContainer\": {\n",
    "        \"ModelPackageName\": model_package_arn\n",
    "    },\n",
    "    \"ExecutionRoleArn\":role\n",
    "} \n",
    "\n",
    "## For Marketplace products, Network isolation flag must be set to true\n",
    "model_creation['EnableNetworkIsolation'] = True\n",
    "\n",
    "model = sagemaker.create_model(**model_creation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: inference with the trained model  (Batch transform)\n",
    "finally the model is ready to serve and you can feed the videos to the model and save the results in output folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded batch data files to s3://sensifai-sagemaker-artifacts/algorithm-validation/audio-event-recognition/test/\n",
      "Created Transform job with name:  sensifai-audio-tagging-bt-2019-02-24-22-02-03\n",
      "Transform job ended with status: Completed\n",
      "CPU times: user 185 ms, sys: 3.73 ms, total: 189 ms\n",
      "Wall time: 6min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "s3_batch_input=\"s3://{}/{}/test/\".format(bucket,prefix)\n",
    "#we already have transfer the data to s3, if you want to copy the files uncomment below code  \n",
    "# s3_bath_input = sess.upload_data(batch_input_dir, bucket, \"{}/test\".format(prefix))\n",
    "print(\"uploaded batch data files to {}\".format(s3_batch_input))\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "batch_job_name = \"sensifai-audio-tagging-bt\" + timestamp\n",
    "batch_output = 's3://{}/{}/output/{}'.format(bucket,prefix, batch_job_name)\n",
    "\n",
    "request = \\\n",
    "{\n",
    "  \"TransformJobName\": batch_job_name,\n",
    "  \"MaxConcurrentTransforms\": 0,\n",
    "  \"MaxPayloadInMB\": 0,\n",
    "  \"ModelName\": model_name,\n",
    "  \"TransformInput\": {\n",
    "    \"DataSource\": {\n",
    "      \"S3DataSource\": {\n",
    "        \"S3DataType\": \"S3Prefix\",\n",
    "        \"S3Uri\": s3_batch_input\n",
    "      }\n",
    "    },\n",
    "    \"ContentType\": \"audio/*\",\n",
    "    \"CompressionType\": \"None\",\n",
    "    \"SplitType\": \"None\"\n",
    "  },\n",
    "  \"TransformOutput\": {\n",
    "    \"S3OutputPath\": batch_output,\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"AssembleWith\": \"Line\"\n",
    "  },\n",
    "  \"TransformResources\": {\n",
    "    \"InstanceType\": \"ml.p2.xlarge\",\n",
    "    \"InstanceCount\": 1\n",
    "  }\n",
    "}\n",
    "\n",
    "sagemaker.create_transform_job(**request)\n",
    "\n",
    "print(\"Created Transform job with name: \", batch_job_name)\n",
    "\n",
    "while(True):\n",
    "    job_info = sagemaker.describe_transform_job(TransformJobName=batch_job_name)\n",
    "    status = job_info['TransformJobStatus']\n",
    "    if status == 'Completed':\n",
    "        print(\"Transform job ended with status: \" + status)\n",
    "        break\n",
    "    if status == 'Failed':\n",
    "        message = job_info['FailureReason']\n",
    "        print('Transform failed with the following error: {}'.format(message))\n",
    "        raise Exception('Transform job failed') \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### download the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "output_path=\"./output\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "!aws s3 cp $batch_output $output_path --recursive\n",
    "\n",
    "#do anything with json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 5 : cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally uncomment and run the code to clean everything up\n",
    "#sagemaker.delete_model(ModelName= model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
