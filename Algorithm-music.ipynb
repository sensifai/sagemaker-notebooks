{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Sensifai](https://sensifai.com) music genre Recognition\n",
    "Sensifai offers one of the most accurate Deep Learning training platform to train your music genre recognition system and incorporate it into your application. This product lets you access Sensifai's advanced music genre recognition algorithm and train it with our own data and validate it with any set you would like. Our video music genre recognition system let you recognize genres of music in audio files.\n",
    "\n",
    "## Step 1: Preparing your data\n",
    "Before starting the training job you have to prepare your data and copy the files to S3.\n",
    "- we have a *VALIDATION_SPILITER* parameter. if it sets to  \"1\" it splits training folder. the algorithm split the data based on the *VALIDATION_PERCENT* parameter. but if it sets to \"0\" you should make a  separate validation folder. \n",
    "in train(and if you have validation) folder, you have to create a subfolder for each class and copy the audio files there. it's recommended to use audios that satisfy the following  conditions:\n",
    "- the algorithm supports most of the common audio formats (mp3,wav,...) and we do not set any limitation on the audio type. However, if the format and sample rate of the test and train files do not match, our algorithm would change the format and sample rate. if the algorithm cannot detect the audio format, skips the file.  either if the file is corrupted, the algorithm skips it. if the number of files that algorithm skip exceeds 50% of all files in the folder, the training procedure exited with the failure code (0).\n",
    "- default sample rate is 22050 Hz and the default format is \"au\". we do not have strict conditions on the sample rate and file format. However, the low-sample rate may have a bad effect on training accuracy.\n",
    "- default shape is a limitation on audio file length. which means if your files are smaller than default shape amount, they will be padded to default shape. and if your files are bigger than default shape extra frames will be removed.\n",
    "- our model is single-GPU.\n",
    "\n",
    "## uploading files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data file to s3://sensifai-sagemaker-artifacts/algorithm-validation/MusicGenreTagging/training/\n",
      "uploaded validation data file to s3://sensifai-sagemaker-artifacts/algorithm-validation/MusicGenreTagging/validation/\n"
     ]
    }
   ],
   "source": [
    "import sagemaker as sage\n",
    "import boto3\n",
    "import time\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = \"your bucket here\"\n",
    "prefix = \"prefix on s3 that the test files are stored\"\n",
    "sess = sage.Session()\n",
    "s3_train=\"s3://{}/{}/training/\".format(bucket,prefix)\n",
    "s3_validation=\"s3://{}/{}/validation/\".format(bucket,prefix)\n",
    "\n",
    "# we already have transfer the data to s3, if you want to copy the files uncomment below code  \n",
    "# s3_train = sess.upload_data(train_data_dir, bucket, \"{}/train\".format(prefix))\n",
    "# s3_validation = sess.upload_data(validation_data_dir, bucket, \"{}/validation\".format(prefix))\n",
    "\n",
    "print(\"uploaded training data file to {}\".format(s3_train))\n",
    "print(\"uploaded validation data file to {}\".format(s3_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### important note :\n",
    "- currently, we support just \"FileMode\" for input mode. In order to insure that there is enough space for transferring and preprocessing files, please set *ValumeSizeinGB* parameter of the *ResourceConfig* section to 2*size_of_dateset-inGB*)\n",
    "\n",
    "## Step 2: Create a model \n",
    "__Training Parameters__\n",
    "\n",
    "| Name                | Description                                | Type    | Min Value | Max Value | IsTunable | IsRequired | DefaultValue |\n",
    "|---------------------|--------------------------------------------|---------|-----------|-----------|-----------|------------|--------------|\n",
    "| WINDOW_SIZE         | Size of window                             | Integer | 256       | 4096      | FALSE     | FALSE      | 2048         |\n",
    "| N_MELS              | Number of Mel frequency bands              | Integer | 32        | 512       | FALSE     | FALSE      | 128          |\n",
    "| SEED                | random seed for spiting data               | Integer | 1         | 100       | FALSE     | FALSE      | 42           |\n",
    "| N_LAYERS            | Number of layers                           | Integer | 1         | 5         | FALSE     | FALSE      | 3            |\n",
    "| FILTER_LENGTH       | length of filter                           | Integer | 1         | 10        | FALSE     | FALSE      | 5            |\n",
    "| CONV_FILTER_COUNT   | Number of convolutional filter             | Integer | 32        | 1024      | FALSE     | FALSE      | 256          |\n",
    "| LSTM_COUNT          | Number of LSTM                             | Integer | 128       | 512       | FALSE     | FALSE      | 256          |\n",
    "| BATCH_SIZE          | Number of batches                          | Integer | 1         | 128       | FALSE     | FALSE      | 32           |\n",
    "| EPOCH_COUNT         | Number of samples for training             | Integer | 1         | 500       | FALSE     | FALSE      | 100          |\n",
    "| DEFAULT_SHAPE       | input frame length to pad                  | Integer | 500       | 1000      | FALSE     | FALSE      | 700          |\n",
    "| VALIDATION_SPLITER | split training data                        | boolean | 1         | 0         | FALSE     | FALSE      | 1            |\n",
    "| VALIDATION_PERCENT  | what percentage of data is for validation. | Integer | 10        | 50        | FALSE     | FALSE      | 30           |\n",
    "\n",
    "|\n",
    "__Run a SageMaker training job__\n",
    "\n",
    "This code will start a training job, wait for it to be done, and report its status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job current status: InProgress\n",
      "Training job ended with status: Completed\n",
      "CPU times: user 159 ms, sys: 17.3 ms, total: 176 ms\n",
      "Wall time: 16min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alg_arn=\"COPY ALGOTITHM ARN HERE \"\n",
    "job_name_prefix = 'train-sensifai-music-tagging'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp\n",
    "\n",
    "create_training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": alg_arn,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": 's3://{}/{}/output/{}'.format(bucket,prefix, job_name_prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.p2.xlarge\",\n",
    "        \"VolumeSizeInGB\": 40\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 14400\n",
    "    },\n",
    "    \"HyperParameters\": \n",
    "{\n",
    "    \"WINDOW_SIZE\" : \"2048\",\n",
    "    \"N_MELS\" : \"128\",\n",
    "    \"SEED\" : \"42\",\n",
    "    \"N_LAYERS\" : \"3\",\n",
    "    \"FILTER_LENGTH\" : \"5\",\n",
    "    \"CONV_FILTER_COUNT\" : \"256\",\n",
    "    \"LSTM_COUNT\" : \"256\",\n",
    "    \"BATCH_SIZE\" : \"32\",\n",
    "    \"EPOCH_COUNT\" : \"2\",\n",
    "    \"DEFAULT_SHAPE\" : \"700\",\n",
    "    \"VALIDATION_SPILITER\" : \"1\",\n",
    "    \"VALIDATION_PERCENT\" : \"0.3\"\n",
    "},\n",
    "\n",
    "\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"training\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": s3_train,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "sagemaker = boto3.client(service_name='sagemaker')\n",
    "sagemaker.create_training_job(**create_training_params)\n",
    "status = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))\n",
    "\n",
    "try:\n",
    "    sagemaker.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "    job_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "    status = job_info['TrainingJobStatus']\n",
    "    print(\"Training job ended with status: \" + status)\n",
    "except:\n",
    "    print('Training failed to start')\n",
    "    message = sagemaker.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "    print('Training failed with the following error: {}'.format(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 :Create a SageMaker model \n",
    "This will set up the model created during training within SageMaker to be used later for recognition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sagemaker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b5ab3ab1c39e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-%Y-%m-%d-%H-%M-%S'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sensifai-music-genre\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mjob_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ModelArtifacts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S3ModelArtifacts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sagemaker' is not defined"
     ]
    }
   ],
   "source": [
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name=\"sensifai-music-genre\" + timestamp\n",
    "job_info = sagemaker.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "model_package_arn =  \"Paste the model ARN\"\n",
    "model_creation = {\n",
    "    \"ModelName\": model_name,\n",
    "    \"PrimaryContainer\": {\n",
    "        \"ModelPackageName\": model_package_arn\n",
    "    },\n",
    "    \"ExecutionRoleArn\":role,\n",
    "    \"EnableNetworkIsolation\": True,\n",
    "}\n",
    "\n",
    "model = sagemaker.create_model(**model_creation)\n",
    "sagemaker.describe_model(ModelName = model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: inference with the trained model  (Batch transform)\n",
    "finally the model is ready to serve and you can feed the videos to the model and save the results in output folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded batch data files to s3://sensifai-sagemaker-artifacts/algorithm-validation/MusicGenreTagging/test/\n",
      "Created Transform job with name:  sensifai-music-tagging-bt-2018-11-19-13-41-08\n",
      "Transform job ended with status: Completed\n",
      "CPU times: user 146 ms, sys: 1.65 ms, total: 148 ms\n",
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "s3_batch_input=\"s3://{}/{}/test/\".format(bucket,prefix)\n",
    "#we already have transfer the data to s3, if you want to copy the files uncomment below code  \n",
    "# s3_bath_input = sess.upload_data(batch_input_dir, bucket, \"{}/test\".format(prefix))\n",
    "print(\"uploaded batch data files to {}\".format(s3_batch_input))\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "batch_job_name = \"sensifai-music-tagging-bt\" + timestamp\n",
    "batch_output = 's3://{}/{}/output/{}'.format(bucket,prefix, batch_job_name)\n",
    "\n",
    "request = \\\n",
    "{\n",
    "  \"TransformJobName\": batch_job_name,\n",
    "  \"MaxConcurrentTransforms\": 0,\n",
    "  \"MaxPayloadInMB\": 0,\n",
    "  \"ModelName\": model_name,\n",
    "  \"TransformInput\": {\n",
    "    \"DataSource\": {\n",
    "      \"S3DataSource\": {\n",
    "        \"S3DataType\": \"S3Prefix\",\n",
    "        \"S3Uri\": s3_batch_input\n",
    "      }\n",
    "    },\n",
    "    \"ContentType\": \"audio/*\",\n",
    "    \"CompressionType\": \"None\",\n",
    "    \"SplitType\": \"None\"\n",
    "  },\n",
    "  \"TransformOutput\": {\n",
    "    \"S3OutputPath\": batch_output,\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"AssembleWith\": \"Line\"\n",
    "  },\n",
    "  \"TransformResources\": {\n",
    "    \"InstanceType\": \"ml.p2.xlarge\",\n",
    "    \"InstanceCount\": 1\n",
    "  }\n",
    "}\n",
    "\n",
    "sagemaker.create_transform_job(**request)\n",
    "\n",
    "print(\"Created Transform job with name: \", batch_job_name)\n",
    "\n",
    "while(True):\n",
    "    job_info = sagemaker.describe_transform_job(TransformJobName=batch_job_name)\n",
    "    status = job_info['TransformJobStatus']\n",
    "    if status == 'Completed':\n",
    "        print(\"Transform job ended with status: \" + status)\n",
    "        break\n",
    "    if status == 'Failed':\n",
    "        message = job_info['FailureReason']\n",
    "        print('Transform failed with the following error: {}'.format(message))\n",
    "        raise Exception('Transform job failed') \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### download the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "output_path=\"./output\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "!aws s3 cp $batch_output $output_path --recursive\n",
    "\n",
    "#do anything with json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 5 : cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally uncomment and run the code to clean everything up\n",
    "#sagemaker.delete_model(ModelName= model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
